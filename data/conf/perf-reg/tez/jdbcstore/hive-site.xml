<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<configuration>
    <property>
        <name>hive.in.test</name>
        <value>true</value>
        <description>Internal marker for test. Used for masking env-dependent values</description>
    </property>
    <property>
        <name>hive.rpc.query.plan</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.llap.execution.mode</name>
        <value>only</value>
    </property>
    <property>
        <name>hive.exec.post.hooks</name>
        <value>
            org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook
        </value>
    </property>
    <property>
        <name>hive.vectorized.execution.mapjoin.native.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.llap.client.consistent.splits</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.reducers.max</name>
        <value>1009</value>
    </property>
    <property>
        <name>hive.zookeeper.kerberos.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.privilege.synchronizer</name>
        <value>false</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
    </property>
    <property>
        <name>hive.cluster.delegation.token.store.class</name>
        <value>org.apache.hadoop.hive.thrift.MemoryTokenStore</value>
    </property>
    <property>
        <name>hive.exec.scratchdir</name>
        <value>${test.tmp.dir}/scratchdir</value>
        <description>Scratch space for Hive jobs</description>
    </property>
    <property>
        <name>hive.compute.query.using.stats</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.tez.sessions.init.threads</name>
        <value>1</value>
    </property>

    <property>
        <name>hive.tez.java.opts</name>
        <value>-server -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB
            -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps
        </value>
    </property>
    <property>
        <name>hive.query.isolation.scan.size.threshold</name>
        <value>400GB</value>
    </property>
    <property>
        <name>hive.tez.min.partition.factor</name>
        <value>0.25</value>
    </property>
    <property>
        <name>hive.optimize.dynamic.partition.hashjoin</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.submit.local.task.via.child</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.orc.split.strategy</name>
        <value>BI</value>
    </property>
    <property>
        <name>hive.server2.max.start.attempts</name>
        <value>5</value>
    </property>
    <property>
        <name>hive.exec.input.listing.max.threads</name>
        <value>100</value>
    </property>

    <property>
        <name>hive.create.as.insert.only</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.mapjoin.bucket.cache.size</name>
        <value>10000</value>
    </property>
    <property>
        <name>hive.optimize.bucketmapjoin.sortedmerge</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.compactor.delta.pct.threshold</name>
        <value>0.1f</value>
    </property>
    <property>
        <name>hive.merge.nway.joins</name>
        <value>false</value>
    </property>


    <property>
        <name>hive.current.database</name>
        <value>tpcds_bin_partitioned_orc_30000</value>
    </property>
    <property>
        <name>hive.optimize.metadataonly</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.compactor.abortedtxn.threshold</name>
        <value>1000</value>
    </property>
    <property>
        <name>hive.query.isolation.enable</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.txn.strict.locking.mode</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.server2.table.type.mapping</name>
        <value>CLASSIC</value>
    </property>
    <property>
        <name>hive.exec.parallel.thread.number</name>
        <value>8</value>
    </property>
    <property>
        <name>hive.optimize.null.scan</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.query.isolation.slots.per.node</name>
        <value>24</value>
    </property>
    <property>
        <name>hive.smbjoin.cache.rows</name>
        <value>10000</value>
    </property>
    <property>
        <name>hive.llap.daemon.yarn.shuffle.port</name>
        <value>25551</value>
    </property>
    <property>
        <name>hive.exec.compress.output</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.driver.parallel.compilation</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.limit.pushdown.memory.usage</name>
        <value>0.04</value>
    </property>
    <property>
        <name>hive.execution.mode</name>
        <value>llap</value>
    </property>
    <property>
        <name>hive.query.isolation.split.size</name>
        <value>128MB</value>
    </property>
    <property>
        <name>hive.auto.convert.sortmerge.join</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.llap.io.allocator.mmap</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.max.created.files</name>
        <value>100000</value>
    </property>
    <property>
        <name>hive.tez.exec.print.summary</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.prewarm.numcontainers</name>
        <value>3</value>
    </property>
    <property>
        <name>hive.tez.dynamic.partition.pruning</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.txn.manager</name>
        <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
    </property>
    <property>
        <name>hive.txn.max.open.batch</name>
        <value>1000</value>
    </property>
    <property>
        <name>hive.map.aggr.hash.percentmemory</name>
        <value>0.5</value>
    </property>
    <property>
        <name>hive.server2.active.passive.ha.recover.sessions</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.fetch.task.aggr</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.llap.kerberos.enabled</name>
        <value>false</value>
    </property>

    <property>
        <name>hive.server2.enable.doAs</name>
        <value>false</value>
    </property>

    <property>
        <name>hive.stats.dbclass</name>
        <value>fs</value>
    </property>
    <property>
        <name>hive.tez.max.partition.factor</name>
        <value>2.0</value>
    </property>
    <property>
        <name>hive.load.data.owner</name>
        <value>hive</value>
    </property>
    <property>
        <name>hive.mapjoin.hybridgrace.hashtable</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.auto.convert.join</name>
        <value>true</value>
    </property>

    <property>
        <name>hive.llap.task.scheduler.timeout.seconds</name>
        <value>300s</value>
    </property>
    <property>
        <name>hive.enforce.sortmergebucketmapjoin</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.vectorized.groupby.flush.percent</name>
        <value>0.1</value>
    </property>
    <property>
        <name>hive.vectorized.execution.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.tez.dynamic.partition.pruning.max.data.size</name>
        <value>104857600</value>
    </property>
    <property>
        <name>hive.merge.orcfile.stripe.level</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.merge.tezfiles</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.map.aggr.hash.min.reduction</name>
        <value>0.99</value>
    </property>
    <property>
        <name>hive.vectorized.groupby.maxentries</name>
        <value>1000000</value>
    </property>
    <property>
        <name>hive.optimize.reducededuplication</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.fetch.task.conversion.threshold</name>
        <value>1073741824</value>
    </property>
    <property>
        <name>hive.server2.idle.operation.timeout</name>
        <value>6h</value>
    </property>
    <property>
        <name>hive.compactor.initiator.on</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.hook.proto.file.per.event</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.map.aggr.hash.force.flush.memory.threshold</name>
        <value>0.9</value>
    </property>
    <property>
        <name>hive.limit.optimize.enable</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.transport.mode</name>
        <value>http</value>
    </property>
    <property>
        <name>hive.merge.size.per.task</name>
        <value>256000000</value>
    </property>
    <property>
        <name>hive.auto.convert.sortmerge.join.to.mapjoin</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.tez.cpu.vcores</name>
        <value>-1</value>
    </property>
    <property>
        <name>hive.txn.timeout</name>
        <value>300</value>
    </property>
    <property>
        <name>hive.cli.print.header</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.lock.manager</name>
        <value></value>
    </property>
    <property>
        <name>hive.server2.thrift.max.worker.threads</name>
        <value>500</value>
    </property>
    <property>
        <name>hive.stats.fetch.partition.stats</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.authentication</name>
        <value>LDAP</value>
    </property>
    <property>
        <name>hive.llap.auto.allow.uber</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.txn.acid.dir.cache.duration</name>
        <value>0</value>
    </property>
    <property>
        <name>hive.tez.exec.inplace.progress</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.active.passive.ha.enable</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.llap.daemon.output.service.send.buffer.size</name>
        <value>256</value>
    </property>
    <property>
        <name>hive.exec.dynamic.partition.mode</name>
        <value>nonstrict</value>
    </property>
    <property>
        <name>hive.server2.webui.port</name>
        <value>10100</value>
    </property>
    <property>
        <name>hive.llap.daemon.memory.per.instance.mb</name>
        <value>49152</value>
    </property>
    <property>
        <name>hive.query.isolation.max.nodes.per.query</name>
        <value>5</value>
    </property>
    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
    </property>
    <property>
        <name>hive.merge.smallfiles.avgsize</name>
        <value>16000000</value>
    </property>
    <property>
        <name>hive.llap.object.cache.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.optimize.constant.propagation</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.orc.splits.include.file.footer</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.llap.io.threadpool.size</name>
        <value>12</value>
    </property>
    <property>
        <name>hive.optimize.bucketmapjoin</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.parallel</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.materializedview.rewriting.incremental</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.tez.log.level</name>
        <value>INFO</value>
    </property>
    <property>
        <name>hive.llap.daemon.output.service.port</name>
        <value>25003</value>
    </property>
    <property>
        <name>hive.optimize.sort.dynamic.partition</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.server2.trusted.domain.use.xff.header</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.dynamic.partition</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.llap.management.rpc.port</name>
        <value>25004</value>
    </property>
    <property>
        <name>hive.tez.container.size</name>
        <value>4096</value>
    </property>
    <property>
        <name>hive.optimize.reducededuplication.min.reducer</name>
        <value>4</value>
    </property>
    <property>
        <name>hive.query.isolation.max.queries</name>
        <value>2</value>
    </property>
    <property>
        <name>hive.compactor.crud.query.based</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.stats.fetch.bitvector</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.zookeeper.client.port</name>
        <value>2181</value>
    </property>
    <property>
        <name>hive.llap.daemon.task.scheduler.enable.preemption</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.heapsize</name>
        <value>1024</value>
    </property>
    <property>
        <name>hive.server2.webui.use.ssl</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.strict.managed.tables</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.mapjoin.optimized.hashtable</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.convert.join.bucket.mapjoin.tez</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.server2.logging.operation.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.stats.autogather</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.failure.hooks</name>
        <value>org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook</value>
    </property>
    <property>
        <name>hive.llap.exec.use.fqdn</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.reducers.bytes.per.reducer</name>
        <value>256000000</value>
    </property>
    <property>
        <name>hive.server2.support.dynamic.service.discovery</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.server2.allow.user.substitution</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.pre.hooks</name>
        <value>org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook</value>
    </property>
    <property>
        <name>hive.mapred.reduce.tasks.speculative.execution</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.execution.engine</name>
        <value>tez</value>
    </property>
    <property>
        <name>hive.vectorized.groupby.checkinterval</name>
        <value>4096</value>
    </property>
    <property>
        <name>hive.llap.io.memory.size</name>
        <value>204800Mb</value>
    </property>
    <property>
        <name>hive.druid.metadata.db.type</name>
        <value>postgresql</value>
    </property>
    <property>
        <name>hive.vectorized.execution.mapjoin.minmax.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.merge.mapfiles</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.stats.fetch.column.stats</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.scheduled.queries.executor.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.async.exec.async.compile</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.thrift.http.port</name>
        <value>10010</value>
    </property>
    <property>
        <name>hive.optimize.index.filter</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.thrift.http.path</name>
        <value>cliservice</value>
    </property>
    <property>
        <name>hive.orc.compute.splits.num.threads</name>
        <value>100</value>
    </property>
    <property>
        <name>hive.tez.bucket.pruning</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.default.fileformat</name>
        <value>TextFile</value>
    </property>
    <property>
        <name>hive.support.concurrency</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.druid.kerberos.enable</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.server2.webui.enable.cors</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.llap.io.memory.mode</name>
        <value>cache</value>
    </property>
    <property>
        <name>hive.server2.async.exec.threads</name>
        <value>200</value>
    </property>
    <property>
        <name>hive.compactor.check.interval</name>
        <value>300</value>
    </property>
    <property>
        <name>hive.tez.cartesian-product.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.llap.auto.enforce.stats</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.merge.rcfile.block.level</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.tez.default.queues</name>
        <value>default</value>
    </property>
    <property>
        <name>hive.server2.tez.initialize.default.sessions</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.compactor.worker.threads</name>
        <value>1</value>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions.pernode</name>
        <value>2000</value>
    </property>
    <property>
        <name>hive.llap.daemon.num.executors</name>
        <value>12</value>
    </property>
    <property>
        <name>hive.compactor.delta.num.threshold</name>
        <value>10</value>
    </property>
    <property>
        <name>hive.compactor.worker.timeout</name>
        <value>86400</value>
    </property>
    <property>
        <name>hive.llap.task.scheduler.locality.delay</name>
        <value>60s</value>
    </property>
    <property>
        <name>hive.server2.idle.session.timeout</name>
        <value>1d</value>
    </property>
    <property>
        <name>hive.repl.cm.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.zookeeper.session.timeout</name>
        <value>150000ms</value>
    </property>
    <property>
        <name>hive.prewarm.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.scheduled.queries.create.as.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.llap.daemon.xmx.headroom</name>
        <value>0%</value>
    </property>
    <property>
        <name>hive.query.results.cache.nontransactional.tables.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.llap.daemon.rpc.port</name>
        <value>25000</value>
    </property>
    <property>
        <name>hive.cbo.enable</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.server2.in.place.progress</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.auto.convert.join.noconditionaltask</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.tez.dynamic.partition.pruning.max.event.size</name>
        <value>1048576</value>
    </property>
    <property>
        <name>hive.vectorized.execution.reduce.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.map.aggr</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.tez.smb.number.waves</name>
        <value>0.5</value>
    </property>
    <property>
        <name>hive.llap.daemon.umbilical.port</name>
        <value>33333</value>
    </property>
    <property>
        <name>hive.tez.input.generate.consistent.splits</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.llap.daemon.service.hosts.enable.compute.groups</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions</name>
        <value>5000</value>
    </property>
    <property>
        <name>hive.server2.webui.cors.allowed.headers</name>
        <value>X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by</value>
    </property>
    <property>
        <name>hive.exec.compress.intermediate</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.server2.authentication.ldap.baseDN</name>
        <value>cn=users,cn=accounts,dc=dwxtpcds,dc=xcu2-8y8x,dc=dev,dc=cldr,dc=work</value>
    </property>
    <property>
        <name>hive.default.fileformat.managed</name>
        <value>ORC</value>
    </property>
    <property>
        <name>hive.llap.io.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.submitviachild</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.tez.input.format</name>
        <value>org.apache.hadoop.hive.ql.io.HiveInputFormat</value>
    </property>
    <property>
        <name>hive.server2.async.exec.wait.queue.size</name>
        <value>1000</value>
    </property>
    <property>
        <name>hive.auto.convert.join.noconditionaltask.size</name>
        <value>1431655765</value>
    </property>
    <property>
        <name>hive.merge.mapredfiles</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.fetch.task.conversion</name>
        <value>more</value>
    </property>
    <property>
        <name>hive.druid.metadata.username</name>
        <value>hive</value>
    </property>
    <property>
        <name>hive.query.results.cache.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.tez.auto.reducer.parallelism</name>
        <value>true</value>
    </property>
    <!-- Metastore properties -->
    <property>
        <name>metastore.create.as.acid</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.metastore.db.type</name>
        <value>POSTGRES</value>
    </property>
    <property>
        <name>hive.metastore.execute.setugi</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.metastore.rawstore.impl</name>
        <value>org.apache.hadoop.hive.metastore.cache.CachedStore</value>
    </property>
    <property>
        <name>hive.metastore.sasl.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.metastore.cache.pinobjtypes</name>
        <value>Table,Database,Type,FieldSchema,Order</value>
    </property>
    <property>
        <name>hive.metastore.event.listeners</name>
        <value></value>
    </property>
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>${test.warehouse.dir}</value>
    </property>
    <property>
        <name>hive.metastore.failure.retries</name>
        <value>2</value>
    </property>
    <property>
        <name>hive.metastore.pre.event.listeners</name>
        <value></value>
    </property>
    <property>
        <name>hive.metastore.client.connect.retry.delay</name>
        <value>5s</value>
    </property>
    <property>
        <name>hive.metastore.authorization.storage.checks</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.metastore.wm.default.pool.size</name>
        <value>1</value>
    </property>
    <property>
        <name>hive.metastore.transactional.event.listeners</name>
        <value>org.apache.hive.hcatalog.listener.DbNotificationListener</value>
    </property>
    <property>
        <name>hive.metastore.dml.events</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.metastore.runworker.in</name>
        <value>hs2</value>
    </property>
    <!-- Metastore connection properties -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://localhost:5432/metastore</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
    </property>
</configuration>